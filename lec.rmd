---
title: "Laboratorio N°3 - Estadística Computacional"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Preguntas 

### 1.1. Distribuciones derivadas de la normal
Teóricamente se explica como surgen distintas distribuciones derivadas de una distribución normal. Comprobaremos
estas afirmaciones en el siguiente ejercicio. En cada pregunta debe graficar el histograma de la
muestra y la función de densidad para comprobar su resultado. Recuerde especificar que parámetros usó y el tamaño de la muestra (ideal > 1000).

1.- Usando muestra normal arbitraria obtenga una distribución normal estándar.

En base a la tranformación entre una distribución Normal $Z$ de  media $\mu=0$ y desviación estandar $\theta=1$ y una distribución Normal $X$ de parametros $\mu=\mu'$ y $\theta=\theta'$
   
   $Z = \frac{(X - \mu')}{\theta'}$ 
   
   Despejando $X$:
   
   $X = Z*\theta' + \mu'$

Esto lo representamos en la siguiente funcion a la que llamaremos $normal$ y retornará una distribucion Normal estandar con media $u$, desviacion estandar $theta$  y $n$ datos.


```{r}
normal <- function(u, theta, n){
  return((rnorm(n)*theta)+u)
}
```

A continuación, se genera una distribución con la función recién definida, esta de media $3$, desviación estandar $1$ y con $1000$ datos.

```{r}
estandar <- normal(3, 1, 1000)
hist(estandar)
```

Finalmente comparamos el histograma obtenido con la función de densidad de la Normal (la función que está incluida en R) para comprobar que si coinciden en su distribución.

```{r}
plot(function(x) dnorm(x), -5, 5, main = "Función de Densidad Distribución Normal")
```

2.- Usando muestras normales estándar obtenga una distribución chi-square. Especifique los parámetros.

Utilizando la definición de la distribucion Chi-square:

$\displaystyle X=Z_{1}^{2}+\cdots +Z_{k}^{2}$

Donde $\displaystyle Z_{i}$ son variables aleatorias normales independientes de media cero y varianza uno. Podemos programar facilmente una función para generar la distribución en base a una suma de normales, utilizando como parametros $n$ (largo de la muestra) y $gl$ (grados de libertad).

```{r}
jicuadrado <- function(n, gl){
  suma <- 0
  for(i in 1:gl){
      suma <- suma+(normal(0,1,1000)^2)
  }
  return(suma)
}
```

Se genera una muestra de distribución Chi-square con $n = 1000$ y $gl = 5$.  
 
```{r}
chisquare <- jicuadrado(1000,5)
hist(chisquare)
```

Comparamos con la función densidad de Chi-square. 

```{r}
plot(function(x, df) dchisq(x, df=5), -1, 20, main = "Función de Densidad")
```


3.- Análogamente, obtenga la distribución t-student.

Al igual que en el item anterior usamos:

$\displaystyle T={\frac {Z}{\sqrt {V/\nu \ }}}$

Donde $T$ es una distribucion T-student, $Z$ es una variable aleatoria con distribución normal y $V$ es una variable continua que sigue una distribución Chi-square. Entonces definimos la distribución T-student según la anterior formula, obviamente obteniendo las distribuciones Normales y Chi-square con las mismas funciones definidas previamente.

```{r}
tstudent <- normal(0,1,1000)/sqrt(jicuadrado(1000, 5) / 5)
hist(tstudent, 12 )
```

Comparamos con la función de densidad de la distribución T-student.

```{r}
plot(function(x, df) dt(x, df=5), -6, 6, main = "Función de Densidad")
```

4.- Análogamente, obtenga la distribución Log-normal.

Según definición de la Log-normal.

$Log-N = e^N$; con $N$ una distribución normal. 

Seguidamente generamos la Log-normal con un distribución normal base de media 0 y varianza 1.

```{r}
lognormal <- exp(normal(0,1,1000))
hist(lognormal, 12)
```

Comparamos con la función densidad.

```{r}
plot(function(x) dlnorm(x), 0, 35, main = "Función de Densidad")
```


### 1.2. Muestreo de distribuciones
Una empresa desea probar sus modelos predictivos, pero no tiene la capacidad de obtener datos nuevos de forma rápida. Usted se encarga de ver como poder solucionar esta situación, y como respuesta propone muestrear distribuciones con parámetros que son obtenidos de expertos del dominio para obtener datos sintéticos. Los datos que la empresa necesita tienen la siguiente estructura:

Índice de asistencia: Número continuo entre 0 y 1, con valor medio 0.8 .

Calidad del trabajo: N´umero continuo entre 0 y 5, con valor medio 4.5 .

Edad: N´umero entero con media 30.

Dinero en miles de pesos: N´umero continuo positivo con media 1000.

Puntaje evaluaci´on: N´umero real con media 50.


Para evitar problemas con parámetros y sistemas de ecuaciones, las varianzas no se especifican.

1.- Explique que distribucióon y sus respectivos parámetros ser´ian correctos para muestrear los datos para la empresa. Hint: Justifique sus respuestas considerando como 
principal factor el soporte de una distribuci´on.

Para el índice de asistencia consideramos que la distribución correcta sería la distribución Beta pues tiene un soporte los valores del intervalo $[0,1]$. Los valores de los parámetros serían $\alpha = 10$ y $\beta = 2.5$.

Para la calidad del trabajo, al igual que el índice de asistencia, utilizamos la distribución Beta pero ajustada al intervalo $[0,5]$. Los valores de los parámetros serían $\alpha = 10$ y $\beta = 1.11$.

Para la edad utilizamos la distribución Gamma con los valores no enteros aproximados al valor entero directamente menor, pues el soporte de la distribución son los números reales positivos. Los parámetros serían $k=2$ y $\theta = 15$.

Para la cantidad de dinero en miles de pesos también utilizamos la distribución Gamma pero con los parámetros $k = 4$ y $\theta = 250$.

Para el puntaje de evaluación, como se trata de un número real utilizamos la distribución Normal Gaussiana, con parámetro $\mu = 50$ y $\delta = 7$ pues se asume que los valores de la evaluación van de 0 a 100.

2.- Obtenga una muestra de 1000 trabajadores y compruebe que sus datos concuerden con los parámetros (medias) especificados anteriormente.

```{r}
indiceAsistencia <- rbeta(1000, 10, 2.5)

calidadTrabajo <- rbeta(1000, 10, 1.11)*5

edad <- floor(rgamma(1000, 2, scale = 15))

dinero <- rgamma(1000, 4, 250)

puntajeEvaluacion <- rnorm(10000, 50, 7)

#Debería ser aproximadamente 0.8
mean(indiceAsistencia)
#Debería ser aproximadamente 4.5
mean(calidadTrabajo)
#Debería ser aproximadamente 30
mean(edad)
#Debería ser aproximadamente 1000
mean(dinero)
#Debería ser aproximadamente 50
mean(puntajeEvaluacion)

```



### 1.3. Máxima verosimilitud

MLE (Maximum Likelihood Estimator) es uno de los estimadores mas conocidos en la inferencia frecuentista debido a las propiedades que posee, a pesar de que muchas veces no es posible obtener este estimador de forma anal´itica.

1.- Defina una funci´on que permita obtener el estimador m´aximo veros´imil para los par´ametros de las distribuciones normal, gamma y weibull respecto de una muestra. Para poder realizar esto es necesario utilizar un solver para optimizar la funci´on de verosimilitud. Explore el uso de optim() (en python, revisar scipy.optimize).

```{r}
LogSimilitud <- function(par, x){
  # par = u - theta - indDistribucion
  n <- length(x)
  f <- rep(0, n)
  for (i in 1:n){
    if(par[3] == 2){
      f[i] <- -dweibull(x[i], shape=par[2], log=TRUE)
    }
    else if(par[3] == 1){
      f[i] <- -dgamma(x[i], shape=par[2], log=TRUE)
    }
    else{
      f[i] <- -dnorm(x[i], par[1], par[2], log=TRUE)
    }
  }
  return(sum(f))
} 
OptimizarLogFunction <- function(dist, u, theta, muest){
  muestra <- 0
  indDistribucion <- 0
  nombre <- "Normal"
  if(dist == 'weibull'){
    indDistribucion <- 2
    nombre <- "WeiBull"
  }
  else if(dist == 'gamma'){
    indDistribucion <- 1
    nombre <- "Gamma"
  }
  LogSimilOptimizado <- optim(
    par = c(u, theta, indDistribucion), 
    fn = LogSimilitud, 
    method=c("L-BFGS-B"), 
    lower = c(0, 0, 0), 
    upper = c(Inf,Inf, 2), 
    x = muest
  )
  print(paste("Maxima Verosimilitud para Distribución", nombre, sep=" "))
  LogSimilOptimizado$par[2]
}

```



2.- Obtenga muestras para las 3 distribuciones anteriores especificando los par´ametros y calcule la m´axima verosimilitud. Compare sus resultados en una tabla.

```{r}
muestNormal <- rnorm(100, 6, 3)
muestGamma <- rgamma(100, shape=3)
muestWeiBull <- rweibull(100, shape=3)
OptimizarLogFunction('normal', 6, 3, muestNormal)
OptimizarLogFunction('gamma', 6, 3, muestGamma)
OptimizarLogFunction('weibull', 6, 3, muestWeiBull)
```


3.- Obtenga los valores del estimador con la funci´on fitdistr() del paquete MASS (Si usa python, use el estimador presente en scipy.stats) y comp´arelos con los valores del estimador obtenidos por su funci´on.
```{r}
library(MASS)
fitdistr(muestNormal, dnorm, list(mean=6,sd = 3), lower = 0)

fitdistr(muestGamma, dgamma, list(shape = 3), lower = 0)

fitdistr(muestWeiBull, dweibull, list(shape = 3), lower = 0)
```


### 1.4. Bootstrapping y estadísticas

Con el uso del remuestreo bootstrap, podemos analizar las distribuciones emp´iricas correspondientes distintas estad´isticas. Usando el paquete "boot" en R (bootstrapped en Python) se facilita el an´alisis de las estad´isticas. Para los siguientes preguntas, usar como m´inimo 5000 muestras booststrap.

Genera una muestra aleatoria normal de 10000 datos con media 10 y varianza 10.

```{r}
muestraNormal4 <- rnorm(10000, 10, 10)
```


Obtenga la distribuci´on emp´irica (histograma) para las siguientes medidas de tendencia central: Media aritm´etica, Media geom´etrica, Media arm´onica, Mediana, Moda.

```{r}
library(boot)
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
bootTest <- function(data, original){
  remuestreo <- sample(data, size=length(data)-1,replace=TRUE)
  armonic<-length(remuestreo)/sum(1/remuestreo)
  desvMed <- (1/length(remuestreo))*(sum(abs(remuestreo-mean(remuestreo))))
  #print(range(remuestreo,na.rm=TRUE)[1])
  IQR <- quantile(remuestreo, 0.25)-quantile(remuestreo, 0.75)
  rangoMed <- (max(remuestreo)+min(remuestreo))/2
  rango <- max(remuestreo)-min(remuestreo)
  return(c(mean(remuestreo), armonic, median(remuestreo), Mode(remuestreo), var(remuestreo)^(0.5), desvMed,  IQR,rango, rangoMed, range(remuestreo,na.rm=TRUE)))
}
boot(data=muestraNormal4, statistic=bootTest, R=5000)
```



Obtenga la distribuci´on emp´irica (histograma) para las siguientes medidas de dispersi´on: 
Desviaci´on est´andar, Desviaci´on Absoluta, Rango, IQR y rango medio.



## 2. Conclusiones