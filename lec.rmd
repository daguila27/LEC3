---
title: "Laboratorio N°3 - Estadística Computacional"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Preguntas 

### 1.1. Distribuciones derivadas de la normal
Teóricamente se explica como surgen distintas distribuciones derivadas de una distribución normal. Comprobaremos
estas afirmaciones en el siguiente ejercicio. En cada pregunta debe graficar el histograma de la
muestra y la función de densidad para comprobar su resultado. Recuerde especificar que parámetros usó y el tamaño de la muestra (ideal > 1000).

1.- Usando muestra normal arbitraria obtenga una distribución normal estándar.
```{r}
normal <- function(u, theta, n){
  return((rnorm(n)*theta)+u)
}
estandar <- normal(0, 1, 1000)
hist(estandar)
plot(function(x) dnorm(x), -5, 5, main = "Función de Densidad")
```

2.- Usando muestras normales estándar obtenga una distribución chi-square. Especifique los parámetros.

```{r}
jicuadrado <- function(n, gl){
  suma <- 0
  for(i in 1:gl){
      suma <- suma+(normal(0,1,1000)^2)
  }
  return(suma)
}
chisquare <- jicuadrado(1000,5)
hist(chisquare)
plot(function(x, df) dchisq(x, df=5), -1, 20, main = "Función de Densidad")
```


3.- Análogamente, obtenga la distribución t-student.
```{r}
tstudent <- normal(0,1,1000)/sqrt(jicuadrado(1000, 5) / 5)
hist(tstudent, 12 )
plot(function(x, df) dt(x, df=5), -6, 6, main = "Función de Densidad")
```

4.- Análogamente, obtenga la distribución Log-normal.

```{r}
lognormal <- exp(normal(0,1,1000))
hist(lognormal, 12)
plot(function(x) dlnorm(x), 0, 35, main = "Función de Densidad")
```


### 1.2. Muestreo de distribuciones
Una empresa desea probar sus modelos predictivos, pero no tiene la capacidad de obtener datos nuevos de forma rápida. Usted se encarga de ver como poder solucionar esta situación, y como respuesta propone muestrear distribuciones con parámetros que son obtenidos de expertos del dominio para obtener datos sintéticos. Los datos que la empresa necesita tienen la siguiente estructura:

Índice de asistencia: Número continuo entre 0 y 1, con valor medio 0.8 .

Calidad del trabajo: N´umero continuo entre 0 y 5, con valor medio 4.5 .

Edad: N´umero entero con media 30.

Dinero en miles de pesos: N´umero continuo positivo con media 1000.

Puntaje evaluaci´on: N´umero real con media 50.


Para evitar problemas con parámetros y sistemas de ecuaciones, las varianzas no se especifican.

1.- Explique que distribucióon y sus respectivos parámetros ser´ian correctos para muestrear los datos para la empresa. Hint: Justifique sus respuestas considerando como 
principal factor el soporte de una distribuci´on.

Para el índice de asistencia consideramos que la distribución correcta sería la distribución Beta pues tiene un soporte los valores del intervalo $[0,1]$. Los valores de los parámetros serían $\alpha = 10$ y $\beta = 2.5$.

Para la calidad del trabajo, al igual que el índice de asistencia, utilizamos la distribución Beta pero ajustada al intervalo $[0,5]$. Los valores de los parámetros serían $\alpha = 10$ y $\beta = 1.11$.

Para la edad utilizamos la distribución Gamma con los valores no enteros aproximados al valor entero directamente menor, pues el soporte de la distribución son los números reales positivos. Los parámetros serían $k=2$ y $\theta = 15$.

Para la cantidad de dinero en miles de pesos también utilizamos la distribución Gamma pero con los parámetros $k = 4$ y $\theta = 250$.

Para el puntaje de evaluación, como se trata de un número real utilizamos la distribución Normal Gaussiana, con parámetro $\mu = 50$ y $\delta = 7$ pues se asume que los valores de la evaluación van de 0 a 100.

2.- Obtenga una muestra de 1000 trabajadores y compruebe que sus datos concuerden con los parámetros (medias) especificados anteriormente.

```{r}
indiceAsistencia <- rbeta(1000, 10, 2.5)

calidadTrabajo <- rbeta(1000, 10, 1.11)*5

edad <- floor(rgamma(1000, 2, scale = 15))

dinero <- rgamma(1000, 4, 250)

puntajeEvaluacion <- rnorm(10000, 50, 7)

#Debería ser aproximadamente 0.8
mean(indiceAsistencia)
#Debería ser aproximadamente 4.5
mean(calidadTrabajo)
#Debería ser aproximadamente 30
mean(edad)
#Debería ser aproximadamente 1000
mean(dinero)
#Debería ser aproximadamente 50
mean(puntajeEvaluacion)

```



### 1.3. Máxima verosimilitud

MLE (Maximum Likelihood Estimator) es uno de los estimadores mas conocidos en la inferencia frecuentista debido a las propiedades que posee, a pesar de que muchas veces no es posible obtener este estimador de forma anal´itica.

1.- Defina una funci´on que permita obtener el estimador m´aximo veros´imil para los par´ametros de las distribuciones normal, gamma y weibull respecto de una muestra. Para poder realizar esto es necesario utilizar un solver para optimizar la funci´on de verosimilitud. Explore el uso de optim() (en python, revisar scipy.optimize).

```{r}
LogSimilitud <- function(par, x){
  # par = u - theta - indDistribucion
  n <- length(x)
  f <- rep(0, n)
  for (i in 1:n){
    if(par[3] == 2){
      f[i] <- -dweibull(x[i], shape=par[2], log=TRUE)
    }
    else if(par[3] == 1){
      f[i] <- -dgamma(x[i], shape=par[2], log=TRUE)
    }
    else{
      f[i] <- -dnorm(x[i], par[1], par[2], log=TRUE)
    }
  }
  return(sum(f))
} 
OptimizarLogFunction <- function(dist, u, theta, muest){
  muestra <- 0
  indDistribucion <- 0
  nombre <- "Normal"
  if(dist == 'weibull'){
    indDistribucion <- 2
    nombre <- "WeiBull"
  }
  else if(dist == 'gamma'){
    indDistribucion <- 1
    nombre <- "Gamma"
  }
  LogSimilOptimizado <- optim(
    par = c(u, theta, indDistribucion), 
    fn = LogSimilitud, 
    method=c("L-BFGS-B"), 
    lower = c(0, 0, 0), 
    upper = c(Inf,Inf, 2), 
    x = muest
  )
  print(paste("Maxima Verosimilitud para Distribución", nombre, sep=" "))
  LogSimilOptimizado$par[2]
}

```



2.- Obtenga muestras para las 3 distribuciones anteriores especificando los par´ametros y calcule la m´axima verosimilitud. Compare sus resultados en una tabla.

```{r}
muestNormal <- rnorm(100, 6, 3)
muestGamma <- rgamma(100, shape=3)
muestWeiBull <- rweibull(100, shape=3)
OptimizarLogFunction('normal', 6, 3, muestNormal)
OptimizarLogFunction('gamma', 6, 3, muestGamma)
OptimizarLogFunction('weibull', 6, 3, muestWeiBull)
```


3.- Obtenga los valores del estimador con la funci´on fitdistr() del paquete MASS (Si usa python, use el estimador presente en scipy.stats) y comp´arelos con los valores del estimador obtenidos por su funci´on.
```{r}
library(MASS)
fitdistr(muestNormal, dnorm, list(mean=6,sd = 3), lower = 0)

fitdistr(muestGamma, dgamma, list(shape = 3), lower = 0)

fitdistr(muestWeiBull, dweibull, list(shape = 3), lower = 0)
```


### 1.4. Bootstrapping y estadísticas

Con el uso del remuestreo bootstrap, podemos analizar las distribuciones emp´iricas correspondientes distintas estad´isticas. Usando el paquete "boot" en R (bootstrapped en Python) se facilita el an´alisis de las estad´isticas. Para los siguientes preguntas, usar como m´inimo 5000 muestras booststrap.

Genera una muestra aleatoria normal de 10000 datos con media 10 y varianza 10.
Obtenga la distribuci´on emp´irica (histograma) para las siguientes medidas de tendencia central: Media aritm´etica, Media geom´etrica, Media arm´onica, Mediana, Moda.

Obtenga la distribuci´on emp´irica (histograma) para las siguientes medidas de dispersi´on: 
Desviaci´on est´andar, Desviaci´on Absoluta, Rango, IQR y rango medio.

## 2. Conclusiones